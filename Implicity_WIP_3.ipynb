{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Construyendo un Sistema de Recomendacion con Feedback Implicito\n",
    "\n",
    "En este ejercicio, desarrollaremos un sistema de recomendacion con feedback implicito utilizando la libreria     [implicit](https://github.com/benfred/implicit).\n",
    "\n",
    "**Pero, a que nos referimos con feedback implicito?**\n",
    "\n",
    "En el primer ejercicio abordamos el filtro colaborativo el cual se basa en la suposicion de que `usuarios similares gustan de las mismas cosas/items`. La matriz usuario-item, o \"matriz de utilidad\" es la piedra angular del filtrado colaborativo. En la matriz de utilidad las filas representan a los usuarios y las columnas representan a los items.\n",
    "\n",
    "\n",
    "\n",
    "Las celdas de la matriz se llenan a partir del grado de preferencia de un usuario a un item determinado y esto se representa en cualquiera de las dos formas:\n",
    "1. **Feedback explicito:** feedback directo hacia un item (por ejemplo el weighted_rating de una pelicula como lo vimos en el [Ejercicio 1](https://experiencia21.tec.mx/courses/481176/assignments/15386625?module_item_id=28379086))\n",
    "\n",
    "2. **Feedback implicito:** comportamiento indirecto hacia un item (por ejemplo el historial de compra, el historial de navegacion o historial de busquedas)\n",
    "\n",
    "El feedback implicito hace suposiciones sobre las preferencias del usuario a partir de las acciones hacia dichos items. Si retomamos el ejemplo si miraste todos los episodios de un show y viste todas las temporadas en una semana, entonces existe la elevada posibilidad de que te guste ese show. Sin embargo, si empiezas a mirar una serie y te detienes a la mitad del primer episodio, entonces es probable que se pueda asumir que no te haya gustado ese show.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Agregando las Librerias\n",
    "\n",
    "Estos seran las librerias que utilizaremos:\n",
    "\n",
    "- [numpy](https://numpy.org/)\n",
    "- [pandas](https://pandas.pydata.org/)\n",
    "- [implicit](https://github.com/benfred/implicit)\n",
    "- scipy (en especifico la clase **csr_matrix**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:01.683438Z",
     "start_time": "2024-06-23T22:25:01.663227Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import implicit\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Cargando los datos\n",
    "\n",
    "Dado que ya te has familiarizado con el dataset de itemLens de los ejercicios 1 y 2 en este ejercicio continuaremos utilizando este dataset que puede encontrar[aqui](https://grouplens.org/datasets/itemlens/), o lo puedes descargar directamente de [aqui](http://files.grouplens.org/datasets/itemlens/ml-latest-small.zip). (Recuerda que estamos trabajando con los datasets `ml-latest-small.zip` )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:12.246274Z",
     "start_time": "2024-06-23T22:25:01.683547Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "steam_games_df_base = pd.read_json('steam_games_df.json', lines=True)\n",
    "\n",
    "reviews_df_base = pd.read_json('reviews_df.json', lines=True)\n",
    "\n",
    "user_items_df_base = pd.read_json('user_items_df.json', lines=True)\n",
    "steam_games_df = steam_games_df_base\n",
    "\n",
    "reviews_df = reviews_df_base\n",
    "\n",
    "user_items_df = user_items_df_base\n",
    "# Preprocesamiento\n",
    "#steam games\n",
    "steam_games_df = steam_games_df[steam_games_df['item_id'].notna()]\n",
    "steam_games_df.reset_index(drop=True, inplace=True)\n",
    "steam_games_df['item_id'] = steam_games_df['item_id'].astype(int)\n",
    "#steam_games_df\n",
    "#reviews \n",
    "reviews_df = reviews_df[reviews_df['item_id'].notna()]\n",
    "reviews_df.reset_index(drop=True, inplace=True)\n",
    "reviews_df['item_id'] = reviews_df['item_id'].astype(int)\n",
    "#Si no esta en nuestra base de steam games. \n",
    "reviews_df = reviews_df[reviews_df['item_id'].isin(steam_games_df['item_id'])]\n",
    "reviews_df = reviews_df.drop(columns=['funny', 'posted', 'last_edited', 'helpful', 'user_url'], axis=1)\n",
    "#reviews_df\n",
    "# Este cambio se hizo antes -> steam_games_df.rename(columns={'id': 'item_id'}, inplace=True)\n",
    "#User Items\n",
    "user_items_df = user_items_df[user_items_df['item_id'].isin(steam_games_df['item_id'])]\n",
    "user_items_df['item_id'] = user_items_df['item_id'].astype(int)\n",
    "user_items_df = user_items_df.drop(columns=['user_url'], axis=1)\n",
    "user_items_df = user_items_df[user_items_df['playtime_forever'] != 0.0]\n",
    "#user_items_df\n",
    "\n",
    "\n",
    "def sigmoid(x, scale=1):\n",
    "    return 1 / (1 + np.exp(-x * scale))\n",
    "\n",
    "\n",
    "user_items_df['log_ptime'] = np.log1p(user_items_df['playtime_forever'])\n",
    "user_items_df['exp_ptime_2week'] = sigmoid(user_items_df['playtime_2weeks'], scale=0.3)\n",
    "max_value = 10\n",
    "user_items_df['exp_ptime_2week'] *= max_value\n",
    "scaler_playtime = MinMaxScaler(feature_range=(0, 5))\n",
    "user_items_df['log_ptime_scaled'] = scaler_playtime.fit_transform(user_items_df[['log_ptime']].values.reshape(-1, 1))\n",
    "\n",
    "scaler_lastweek = MinMaxScaler(feature_range=(0, 5))\n",
    "user_items_df['exp_ptime_2week_scaled'] = scaler_lastweek.fit_transform(\n",
    "    user_items_df[['exp_ptime_2week']].values.reshape(-1, 1))\n",
    "n = 0.6  # Peso para el tiempo de juego en las últimas dos semanas\n",
    "m = 0.4  # Peso para el tiempo de juego total\n",
    "user_items_df['combined_rating'] = n * user_items_df['exp_ptime_2week_scaled'] + m * user_items_df['log_ptime_scaled']\n",
    "user_items_df = pd.merge(user_items_df, reviews_df[['user_id', 'item_id', 'recommend']], on=['user_id', 'item_id'],\n",
    "                         how='left')\n",
    "#result = pd.merge(user_items_df, reviews_df, on=['user_id', 'item_id'],how='left')\n",
    "\n",
    "#user_items_df\n",
    "#result\n",
    "user_items_df['weighted_rating'] = user_items_df['combined_rating'] * (1 + user_items_df['recommend'].fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos el contenido de user_items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:12.255205Z",
     "start_time": "2024-06-23T22:25:12.247835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   item_id               item_name  playtime_forever  playtime_2weeks  \\\n0       10          Counter-Strike               6.0              0.0   \n1       30           Day of Defeat               7.0              0.0   \n2      300   Day of Defeat: Source            4733.0              0.0   \n3      240  Counter-Strike: Source            1853.0              0.0   \n4     3830             Psychonauts             333.0              0.0   \n\n             user_id  log_ptime  exp_ptime_2week  log_ptime_scaled  \\\n0  76561197970982479   1.945910              5.0          0.493976   \n1  76561197970982479   2.079442              5.0          0.546629   \n2  76561197970982479   8.462526              5.0          3.063538   \n3  76561197970982479   7.525101              5.0          2.693903   \n4  76561197970982479   5.811141              5.0          2.018072   \n\n   exp_ptime_2week_scaled  combined_rating  recommend  weighted_rating  \n0                     0.0         0.197590        NaN         0.197590  \n1                     0.0         0.218651        NaN         0.218651  \n2                     0.0         1.225415        NaN         1.225415  \n3                     0.0         1.077561        NaN         1.077561  \n4                     0.0         0.807229        NaN         0.807229  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>item_name</th>\n      <th>playtime_forever</th>\n      <th>playtime_2weeks</th>\n      <th>user_id</th>\n      <th>log_ptime</th>\n      <th>exp_ptime_2week</th>\n      <th>log_ptime_scaled</th>\n      <th>exp_ptime_2week_scaled</th>\n      <th>combined_rating</th>\n      <th>recommend</th>\n      <th>weighted_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>Counter-Strike</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>76561197970982479</td>\n      <td>1.945910</td>\n      <td>5.0</td>\n      <td>0.493976</td>\n      <td>0.0</td>\n      <td>0.197590</td>\n      <td>NaN</td>\n      <td>0.197590</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>Day of Defeat</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>76561197970982479</td>\n      <td>2.079442</td>\n      <td>5.0</td>\n      <td>0.546629</td>\n      <td>0.0</td>\n      <td>0.218651</td>\n      <td>NaN</td>\n      <td>0.218651</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>300</td>\n      <td>Day of Defeat: Source</td>\n      <td>4733.0</td>\n      <td>0.0</td>\n      <td>76561197970982479</td>\n      <td>8.462526</td>\n      <td>5.0</td>\n      <td>3.063538</td>\n      <td>0.0</td>\n      <td>1.225415</td>\n      <td>NaN</td>\n      <td>1.225415</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>240</td>\n      <td>Counter-Strike: Source</td>\n      <td>1853.0</td>\n      <td>0.0</td>\n      <td>76561197970982479</td>\n      <td>7.525101</td>\n      <td>5.0</td>\n      <td>2.693903</td>\n      <td>0.0</td>\n      <td>1.077561</td>\n      <td>NaN</td>\n      <td>1.077561</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3830</td>\n      <td>Psychonauts</td>\n      <td>333.0</td>\n      <td>0.0</td>\n      <td>76561197970982479</td>\n      <td>5.811141</td>\n      <td>5.0</td>\n      <td>2.018072</td>\n      <td>0.0</td>\n      <td>0.807229</td>\n      <td>NaN</td>\n      <td>0.807229</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_items_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio, definiremos el weighted_rating de las peliculas como el numero de veces que un usuario las ha mirado. Por ejemplo, si Jimena (una usuaria en nuestro dataset) le dio a la pelicula de`Batman` un weighted_rating de 1 y a `Jurassic Park` un weighted_rating de 5, podemos asumir que ha mirado la pelicula de Batman una vez y la de Jurassic Park un total de 5 veces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA ###\n",
    "\n",
    "Es necesario realizar una limpieza del dataset antes de proceder con el ejercicio pues contiene registros duplicados que arrojaran un problema en el numero de registros de los titulos de las peliculas. \n",
    "\n",
    "Para lo cual es necesario eliminar duplicados que contiene el dataset de peliculas y proceder con el ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Transformando los datos\n",
    "\n",
    "Tal y como lo hicimos en el [Ejercicio 1](https://experiencia21.tec.mx/courses/481176/assignments/15386625?module_item_id=28379086), necesitamos transformar el dataframe de `weighted_ratings` a una matriz usuario-item donde las filas representan a los usuarios y las columnas representan a las peliculas. Las celdas en esta matriz contendran el feedback implicito que en este caso es el numero de veces que un usuario ha visto una pelicula.\n",
    "\n",
    "La funcion  `create_X()` crea una matriz de dispersion **X** con 4 diccionarios de mapeo:\n",
    "\n",
    "- **user_mapper:** mapea user id al user index\n",
    "- **item_mapper:** mapea item id al item index\n",
    "- **user_inv_mapper:** mapea user index al user id\n",
    "- **item_inv_mapper:** mapea item index al item id\n",
    "\n",
    "Necesitamos estos diccionario por que hay que mapear las filas y columnas con la matriz de utilidad que les corresponde al user ID con su item ID respectivamente.\n",
    "\n",
    "Esta matriz dispersa **usuario-item** es una matriz que se obtiene al `usar scipy.sparse.csr_matrix`que almacena los datos de una manera dispersa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:12.257760Z",
     "start_time": "2024-06-23T22:25:12.255787Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_X(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Generates a sparse matrix from user_items_df dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas dataframe\n",
    "    \n",
    "    Returns:\n",
    "        X: sparse matrix\n",
    "        user_mapper: dict that maps user id's to user indices\n",
    "        user_inv_mapper: dict that maps user indices to user id's\n",
    "        item_mapper: dict that maps item id's to item indices\n",
    "        item_inv_mapper: dict that maps item indices to item id's\n",
    "    \"\"\"\n",
    "    N = df['user_id'].nunique()\n",
    "    M = df['item_id'].nunique()\n",
    "\n",
    "    user_mapper = dict(zip(np.unique(df[\"user_id\"]), list(range(N))))\n",
    "    item_mapper = dict(zip(np.unique(df[\"item_id\"]), list(range(M))))\n",
    "    \n",
    "    user_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"user_id\"])))\n",
    "    item_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"item_id\"])))\n",
    "    \n",
    "    user_index = [user_mapper[i] for i in df['user_id']]\n",
    "    item_index = [item_mapper[i] for i in df['item_id']]\n",
    "\n",
    "    X = csr_matrix((df[\"weighted_rating\"], (item_index, user_index)), shape=(M, N))\n",
    "    \n",
    "    return X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:17.180845Z",
     "start_time": "2024-06-23T22:25:12.425031Z"
    }
   },
   "outputs": [],
   "source": [
    "X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper = create_X(user_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando los Mapeos de los titulos de las peliculas\n",
    "\n",
    "Necesitamos traducir el titulo de una pelicula a partir de su indice en la matriz usuario-item y vice versa. Vamos a crear dos funciones que nos ayuden con esta traduccion.\n",
    "\n",
    "- `get_item_index()` - convierte el titulo de una pelicula a su indice. Hace uso de la funcion de comparacion de strings que se le pasan a [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy) \n",
    " para obtener el titulo de una pelicula que se le pase. Esto significa que no necesitamos saber la forma de escribir o el formato de una pelicula para obtener su indice.\n",
    "\n",
    "- `get_item_item_name()` - convierte el indice de una pelicula a su titulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:18.158394Z",
     "start_time": "2024-06-23T22:25:17.183899Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "def item_finder(item_name):\n",
    "    all_item_names = user_items_df['item_name'].unique().tolist()\n",
    "    closest_match = process.extractOne(item_name,all_item_names)\n",
    "    return closest_match[0]\n",
    "\n",
    "item_item_name_mapper = dict(zip(user_items_df['item_name'], user_items_df['item_id']))\n",
    "item_item_name_inv_mapper = dict(zip(user_items_df['item_id'], user_items_df['item_name']))\n",
    "\n",
    "def get_item_index(item_name):\n",
    "    fuzzy_item_name = item_finder(item_name)\n",
    "    item_id = item_item_name_mapper[fuzzy_item_name]\n",
    "    item_idx = item_mapper[item_id]\n",
    "    return item_idx\n",
    "\n",
    "def get_item_item_name(item_idx): \n",
    "    item_id = item_inv_mapper[item_idx]\n",
    "    item_name = item_item_name_inv_mapper[item_id]\n",
    "    return item_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar esta funcion para obtener el indice de `Jurassic Park`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:19.333826Z",
     "start_time": "2024-06-23T22:25:18.355327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1769"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_item_index('warframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizemos el indice obtenido con la funcion `get_item_item_name()`. Tendremos que obtener el titulo de Jurassic Park."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:19.336230Z",
     "start_time": "2024-06-23T22:25:19.333216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Warframe'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_item_item_name(1769)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos comprobar que las funciones nos permitiran interpretar las recomendaciones obtenidas del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Construyendo el modelo de modelo de Recomendacion de Feedback Implicito\n",
    "\n",
    "Una vez que hemos transformado nuestros datos ahora si podemos empezar a construir nuestro modelo de recomendacion.\n",
    "\n",
    "\n",
    "La libreria [implicit](https://github.com/benfred/implicit) esta basada en un factorizacion de matrices (tomado del algebra lineal). Esto nos permite hallar caracteristicas\n",
    "latentes que se esconden en las interacciones entre los usuarios y las peliculas. Estas caracteristicas latentes nos brindan una representacion mas compacta de los gustos\n",
    "de los usuarios y la descripcion de un item. La factorizacion matricial es particularmente util para datos muy dispersos y puede mejorar la calidad de las recomendaciones\n",
    "obtenidas. El algoritmo opera al factorizar la matris usuario-item en dos matrices:\n",
    "\n",
    "- matriz usuario-factorers  (n_users, k)\n",
    "- matriz item-factorers     (k, n_items)\n",
    "\n",
    "Reduciremos las dimensiones de nuestra matriz original a nuestras dimensiones particulares. No es posible interpretar cada caracteristica latente $k$. Sin embargo,\n",
    "podemos suponer que una caracteristica latente puede representar a los usuarios que gusten de comedia romantica de los 90s, mientras que otra caracteristica lantente\n",
    "puede representar a peliculas independientes extranjeras.\n",
    "\n",
    "\n",
    "$$X_{mn} \\approx P_{mk} \\times Q_{nk}^T = \\hat{X}$$\n",
    "\n",
    "\n",
    "\n",
    "En el caso de una factorizacion matricial tradicional como [SVD](https://www.freecodecamp.org/news/singular-value-decomposition-vs-matrix-factorization-in-recommender-systems-b1e99bc73599/) lo que hariamos seria intentar resolver la factorizacion de una sola vez, sin embargo esto resultaria muy costoso computacionalmente. Otra forma de atacar este problem es utilizando una tecnica denominada\n",
    "[Minimos Cuadrados Alternos, Alternating Least Squares (ALS)](https://sophwats.github.io/2018-04-05-gentle-als.html). Ocupando ALS, podemos resolver una matriz de factores a la vez:\n",
    "\n",
    "- Paso 1: Fijamos la matriz de factores de usuario (user-factor) y resolvemos la matriz de factores de elementos (item-factor)\n",
    "- Paso 2: Fijamos la matriz de factores de elementos (item-factor) y resolvemos la matriz de factores de usuario (user-factor)\n",
    "\n",
    "Al alternar los pasos 1 y 2 hasta que el producto punto de la matriz de factores de elementos (item-factor) y la matriz de factores de usuarios (user-item) es aproximadamente igual a la matrix original X (user-item). Este procedimiento es comptacionalmente menos costoso y puede ser parelelizado.\n",
    "\n",
    "La libreria `implicit` implementa una factorizacion matricial utilizando ALS (puedes consultar los detalles [aqui](https://implicit.readthedocs.io/en/latest/als.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:19.385722Z",
     "start_time": "2024-06-23T22:25:19.335696Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 12 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo viene con algunos hyperparametros que deben ser ajustados para generar resultados optimos:\n",
    "\n",
    "- los factores ($k$): numero de factores latentes,\n",
    "- regularizacion ($\\lambda$): evita que el modelo caiga en overfitting durante el entrenamiento\n",
    "\n",
    "Para este ejercicio definiremos $k = 50$ y $\\lambda = 0.01$ como los valores a utilizar. \n",
    "\n",
    "El siguiente paso ahora es ajustar nuestro modelo a la matriz user-item.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:55.963244Z",
     "start_time": "2024-06-23T22:25:19.362713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "182a1184e9ae45c0bee2b9ad56491cf6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(X.T.tocsr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ahora pongamos a prueba las recomendaciones de nuestro modelo. Podemos utilizar el metodo `similar_items()` que nos muestra las peliculas mas relevantes dada una pelicula en especifico. De igual forma, podemos utilizar la funcion `get_item_index()` para obtener el indice de la pelicula si es que es una pelicula que nos interesa a partir de las recomendaciones obtenidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:57.874300Z",
     "start_time": "2024-06-23T22:25:56.456159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 527,  526,  790,  789,  520, 5753,  791,  523,  522, 1326],\n       dtype=int32),\n array([1.0000001 , 0.88668185, 0.77981985, 0.7647837 , 0.7171778 ,\n        0.67646414, 0.67304975, 0.6524359 , 0.6365224 , 0.56436807],\n       dtype=float32))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_of_interest = 'Fallout : New Vegas'\n",
    "\n",
    "item_index = get_item_index(item_of_interest)\n",
    "related = model.similar_items(item_index)\n",
    "related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que obtenemos de `similar_items()` no es facil de leer por lo que necesitamos de la funcion `get_item_item_name()` para interpretar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.250032Z",
     "start_time": "2024-06-23T22:25:57.842366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por que jugaste Fallout: New Vegas te pueden interesar los siguientes:\n",
      "Fallout 3 - Game of the Year Edition\n",
      "Fallout 2\n",
      "Fallout\n",
      "Fallout 3\n",
      "Fallout 4\n",
      "Fallout Tactics\n",
      "The Elder Scrolls IV: Oblivion \n",
      "The Elder Scrolls III: Morrowind\n",
      "Fable - The Lost Chapters\n"
     ]
    }
   ],
   "source": [
    "print(f\"Por que jugaste {item_finder(item_of_interest)} te pueden interesar los siguientes:\")\n",
    "for t, r in zip(related[0], related[1]):\n",
    "    \n",
    "    recommended_item_name = get_item_item_name(t)\n",
    "    if recommended_item_name != item_finder(item_of_interest):\n",
    "        print(recommended_item_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al usar el weighted_rating de los usuarios como feedback implicito, los resultados se ven bien. Intenta cambiando la variable `item_of_interest`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Generando las recomendaciones del usuario\n",
    "\n",
    "Una caracteristica interesante de `implicit` es que puedes obtener recomendaciones personalizadas para un usuario determinado. Intentemos ver los resultados con un usuario especifico de nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.251812Z",
     "start_time": "2024-06-23T22:26:14.249391Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id = 'evcentric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.593022Z",
     "start_time": "2024-06-23T22:26:14.441609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de peliculas rankeadas por el usuario evcentric es de: 100\n"
     ]
    }
   ],
   "source": [
    "user_user_items_df = user_items_df[user_items_df['user_id']==user_id]\n",
    "user_user_items_df = user_user_items_df.sort_values('weighted_rating', ascending=False)\n",
    "print(f\"El numero de peliculas rankeadas por el usuario {user_id} es de: {user_user_items_df['item_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:05:25.757919Z",
     "start_time": "2024-06-16T22:05:25.752109Z"
    }
   },
   "source": [
    "En este caso vemos que el usuario 90 miro 54 peliculas y el weighted_rating de su favoritas son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.783721Z",
     "start_time": "2024-06-23T22:26:14.776676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     item_id                item_name  playtime_forever  playtime_2weeks  \\\n751   466170  Idling to Rule the Gods           28545.0           1554.0   \n692   230410                 Warframe            1381.0             59.0   \n712   275850             No Man's Sky            1219.0            141.0   \n711   211820                Starbound              67.0             67.0   \n694   224500                 Gnomoria           13618.0              0.0   \n\n       user_id  log_ptime  exp_ptime_2week  log_ptime_scaled  \\\n751  evcentric  10.259272             10.0          3.772012   \n692  evcentric   7.231287             10.0          2.578049   \n712  evcentric   7.106606             10.0          2.528886   \n711  evcentric   4.219508             10.0          1.390477   \n694  evcentric   9.519221              5.0          3.480203   \n\n     exp_ptime_2week_scaled  combined_rating  recommend  weighted_rating  \n751                     5.0         4.508805        NaN         4.508805  \n692                     5.0         4.031220        NaN         4.031220  \n712                     5.0         4.011555        NaN         4.011555  \n711                     5.0         3.556191        NaN         3.556191  \n694                     0.0         1.392081        1.0         2.784162  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>item_name</th>\n      <th>playtime_forever</th>\n      <th>playtime_2weeks</th>\n      <th>user_id</th>\n      <th>log_ptime</th>\n      <th>exp_ptime_2week</th>\n      <th>log_ptime_scaled</th>\n      <th>exp_ptime_2week_scaled</th>\n      <th>combined_rating</th>\n      <th>recommend</th>\n      <th>weighted_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>751</th>\n      <td>466170</td>\n      <td>Idling to Rule the Gods</td>\n      <td>28545.0</td>\n      <td>1554.0</td>\n      <td>evcentric</td>\n      <td>10.259272</td>\n      <td>10.0</td>\n      <td>3.772012</td>\n      <td>5.0</td>\n      <td>4.508805</td>\n      <td>NaN</td>\n      <td>4.508805</td>\n    </tr>\n    <tr>\n      <th>692</th>\n      <td>230410</td>\n      <td>Warframe</td>\n      <td>1381.0</td>\n      <td>59.0</td>\n      <td>evcentric</td>\n      <td>7.231287</td>\n      <td>10.0</td>\n      <td>2.578049</td>\n      <td>5.0</td>\n      <td>4.031220</td>\n      <td>NaN</td>\n      <td>4.031220</td>\n    </tr>\n    <tr>\n      <th>712</th>\n      <td>275850</td>\n      <td>No Man's Sky</td>\n      <td>1219.0</td>\n      <td>141.0</td>\n      <td>evcentric</td>\n      <td>7.106606</td>\n      <td>10.0</td>\n      <td>2.528886</td>\n      <td>5.0</td>\n      <td>4.011555</td>\n      <td>NaN</td>\n      <td>4.011555</td>\n    </tr>\n    <tr>\n      <th>711</th>\n      <td>211820</td>\n      <td>Starbound</td>\n      <td>67.0</td>\n      <td>67.0</td>\n      <td>evcentric</td>\n      <td>4.219508</td>\n      <td>10.0</td>\n      <td>1.390477</td>\n      <td>5.0</td>\n      <td>3.556191</td>\n      <td>NaN</td>\n      <td>3.556191</td>\n    </tr>\n    <tr>\n      <th>694</th>\n      <td>224500</td>\n      <td>Gnomoria</td>\n      <td>13618.0</td>\n      <td>0.0</td>\n      <td>evcentric</td>\n      <td>9.519221</td>\n      <td>5.0</td>\n      <td>3.480203</td>\n      <td>0.0</td>\n      <td>1.392081</td>\n      <td>1.0</td>\n      <td>2.784162</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_user_items_df = user_items_df[user_items_df['user_id']==user_id]\n",
    "user_user_items_df = user_user_items_df.sort_values('weighted_rating', ascending=False)\n",
    "top_5 = user_user_items_df.head()\n",
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las peliculas con el menor weighted_rating son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.789434Z",
     "start_time": "2024-06-23T22:26:14.785822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     item_id                     item_name  playtime_forever  playtime_2weeks  \\\n702   239350                      Spelunky               5.0              0.0   \n675     2290                    Final DOOM               4.0              0.0   \n669    67000                The Polynomial               4.0              0.0   \n715   285310  RollerCoaster Tycoon: Deluxe               2.0              0.0   \n725   328080           Retro-Pixel Castles               2.0              0.0   \n\n       user_id  log_ptime  exp_ptime_2week  log_ptime_scaled  \\\n702  evcentric   1.791759              5.0          0.433193   \n675  evcentric   1.609438              5.0          0.361302   \n669  evcentric   1.609438              5.0          0.361302   \n715  evcentric   1.098612              5.0          0.159879   \n725  evcentric   1.098612              5.0          0.159879   \n\n     exp_ptime_2week_scaled  combined_rating  recommend  weighted_rating  \n702                     0.0         0.173277        NaN         0.173277  \n675                     0.0         0.144521        NaN         0.144521  \n669                     0.0         0.144521        NaN         0.144521  \n715                     0.0         0.063951        NaN         0.063951  \n725                     0.0         0.063951        NaN         0.063951  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>item_name</th>\n      <th>playtime_forever</th>\n      <th>playtime_2weeks</th>\n      <th>user_id</th>\n      <th>log_ptime</th>\n      <th>exp_ptime_2week</th>\n      <th>log_ptime_scaled</th>\n      <th>exp_ptime_2week_scaled</th>\n      <th>combined_rating</th>\n      <th>recommend</th>\n      <th>weighted_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>702</th>\n      <td>239350</td>\n      <td>Spelunky</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>evcentric</td>\n      <td>1.791759</td>\n      <td>5.0</td>\n      <td>0.433193</td>\n      <td>0.0</td>\n      <td>0.173277</td>\n      <td>NaN</td>\n      <td>0.173277</td>\n    </tr>\n    <tr>\n      <th>675</th>\n      <td>2290</td>\n      <td>Final DOOM</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>evcentric</td>\n      <td>1.609438</td>\n      <td>5.0</td>\n      <td>0.361302</td>\n      <td>0.0</td>\n      <td>0.144521</td>\n      <td>NaN</td>\n      <td>0.144521</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>67000</td>\n      <td>The Polynomial</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>evcentric</td>\n      <td>1.609438</td>\n      <td>5.0</td>\n      <td>0.361302</td>\n      <td>0.0</td>\n      <td>0.144521</td>\n      <td>NaN</td>\n      <td>0.144521</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>285310</td>\n      <td>RollerCoaster Tycoon: Deluxe</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>evcentric</td>\n      <td>1.098612</td>\n      <td>5.0</td>\n      <td>0.159879</td>\n      <td>0.0</td>\n      <td>0.063951</td>\n      <td>NaN</td>\n      <td>0.063951</td>\n    </tr>\n    <tr>\n      <th>725</th>\n      <td>328080</td>\n      <td>Retro-Pixel Castles</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>evcentric</td>\n      <td>1.098612</td>\n      <td>5.0</td>\n      <td>0.159879</td>\n      <td>0.0</td>\n      <td>0.063951</td>\n      <td>NaN</td>\n      <td>0.063951</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_5 = user_user_items_df[user_user_items_df['weighted_rating']<5].tail()\n",
    "bottom_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las preferencias anteriores, podemos inferir algo acerca del usuario 90. Veamos que recomendaciones se pueden generar para este usuario en particular.\n",
    "\n",
    "Utilizaremos `recommend()` que utiliza el indice del usuario y lo transpone con la matriz user-item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.913393Z",
     "start_time": "2024-06-23T22:26:14.788078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array([1613, 6764, 2263, 2389, 1007, 1791, 1276, 4711,   19,    6],\n       dtype=int32),\n array([0.5589234 , 0.4962295 , 0.4939361 , 0.4539813 , 0.44857654,\n        0.3932966 , 0.3927964 , 0.38852093, 0.38602477, 0.3384616 ],\n       dtype=float32))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = X.T.tocsr()\n",
    "user_idx = user_mapper[user_id]\n",
    "recommendations = model.recommend(user_idx, X_t[user_idx])\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No podemos interpretar los resultados obtenidos pues estan listados los indices. Hagamos una conversion del indice al titulo de las peliculas recomendadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.918637Z",
     "start_time": "2024-06-23T22:26:14.845267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kerbal Space Program\n",
      "Stardew Valley\n",
      "Cities: Skylines\n",
      "Borderlands: The Pre-Sequel\n",
      "Saints Row: The Third\n",
      "Killing Floor 2\n",
      "XCOM: Enemy Unknown\n",
      "ARK: Survival Evolved\n",
      "Left 4 Dead\n",
      "Half-Life\n"
     ]
    }
   ],
   "source": [
    "for t, r in zip(recommendations[0], recommendations[1]):\n",
    "    recommended_item_name = get_item_item_name(t)\n",
    "    print(recommended_item_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# \n",
    "# def process_user(user_id, numero_recom):\n",
    "#     user_ra = user_items_df[user_items_df['user_id'] == user_id]\n",
    "#     ground_truth = user_ra['item_id'].tolist()\n",
    "#     \n",
    "#     user_idx = user_mapper[user_id]\n",
    "#     recommendations_s = model.recommend(user_idx, X_t[user_idx])\n",
    "#     \n",
    "#     return user_id, recommendations_s, ground_truth\n",
    "# \n",
    "# def gen_recom_ground_truth_implicity(numero_recom, num_cores):\n",
    "#     recommendations = {}\n",
    "#     ground_truth = {}\n",
    "#     # Fetch unique user IDs\n",
    "#     unique_user_ids = user_items_df['user_id'].unique()\n",
    "#     \n",
    "#     # Create a Pool with the specified number of cores\n",
    "#     with Pool(num_cores) as pool:\n",
    "#         results = list(tqdm(pool.imap(lambda user_id: process_user(user_id, numero_recom), unique_user_ids),\n",
    "#                             total=len(unique_user_ids), desc=\"Processing Users\"))\n",
    "# \n",
    "#     # Collect results from multiprocessing\n",
    "#     for user_id, user_recommendations, user_ground_truth in results:\n",
    "#         recommendations[user_id] = user_recommendations\n",
    "#         ground_truth[user_id] = user_ground_truth\n",
    "# \n",
    "#     return recommendations, ground_truth\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.953955Z",
     "start_time": "2024-06-23T22:26:14.862802Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#user_indices = np.arange(X_t.shape[0])\n",
    "#ids, scores = model.recommend(user_indices, X_t, N=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.954165Z",
     "start_time": "2024-06-23T22:26:14.886566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "#recommendations_dict_imp_direct = {user_inv_mapper[i]: ids[i].tolist() for i in range(len(user_indices))}\n",
    "#recommendations_dict_imp_direct"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.954241Z",
     "start_time": "2024-06-23T22:26:14.888931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta sección se ejecuto anteriormente y se guardaron los resultados para evitar el tiempo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# if __name__ == '__main__':\n",
    "#     start_time = time.time()\n",
    "#     numero_recom = 10\n",
    "#     num_cores = 10\n",
    "#     recommendations_dict_imp, ground_truth_dict_imp = gen_recom_ground_truth_implicity(numero_recom, num_cores)\n",
    "#     end_time = time.time()\n",
    "# \n",
    "#     print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "print(\"Esta sección se ejecuto anteriormente y se guardaron los resultados para evitar el tiempo\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:14.956618Z",
     "start_time": "2024-06-23T22:26:14.894856Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pickle\n",
    "time_implicity = 9290.773648023605\n",
    "# with open('recommendations_dict_imp.pkl', 'wb') as f:\n",
    "#     pickle.dump(recommendations_dict_imp, f)\n",
    "# \n",
    "# with open('ground_truth_dict_imp.pkl', 'wb') as f:\n",
    "#     pickle.dump(ground_truth_dict_imp, f)\n",
    "\n",
    "#Reconstrucción de datos\n",
    "with open('recommendations_dict_imp.pkl', 'rb') as f:\n",
    "    recommendations_dict_imp = pickle.load(f)\n",
    "\n",
    "with open('ground_truth_dict_imp.pkl', 'rb') as f:\n",
    "    ground_truth_dict_imp = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:15.229810Z",
     "start_time": "2024-06-23T22:26:14.898432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "recommendations_imp = [recommendations_dict_imp[user][0].tolist() for user in recommendations_dict_imp]\n",
    "ground_truth_imp = [ground_truth_dict_imp[user] for user in ground_truth_dict_imp]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:15.378259Z",
     "start_time": "2024-06-23T22:26:15.376653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7227867224313563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Extract predicted and actual ratings\n",
    "predicted_ratings = []\n",
    "actual_ratings = []\n",
    "\n",
    "for user in ground_truth_dict_imp:\n",
    "    if user in recommendations_dict_imp:\n",
    "        predicted_items = recommendations_dict_imp[user][0]\n",
    "        predicted_scores = recommendations_dict_imp[user][1]\n",
    "\n",
    "        ground_truth_items = ground_truth_dict_imp[user]\n",
    "\n",
    "        # Match predicted ratings with actual ratings\n",
    "        for item in ground_truth_items:\n",
    "            if item in predicted_items:\n",
    "                index = np.where(predicted_items == item)[0][0]\n",
    "                predicted_ratings.append(predicted_scores[index])\n",
    "                actual_ratings.append(1)  # Assuming ground truth ratings are implicit feedback with rating = 1\n",
    "\n",
    "# Convert to numpy arrays\n",
    "predicted_ratings = np.array(predicted_ratings)\n",
    "actual_ratings = np.array(actual_ratings)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_impli = sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "print(\"RMSE:\", rmse_impli)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T22:26:19.290713Z",
     "start_time": "2024-06-23T22:26:15.380436Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "def truncated_precision_at_k(actual, predicted, k=10):\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    predicted = predicted[:k]\n",
    "    relevant = len(set(predicted) & set(actual))\n",
    "    return relevant / min(k, len(actual))\n",
    "\n",
    "def truncated_average_precision_at_k(actual, predicted, k=10):\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(k, len(actual))\n",
    "\n",
    "def hit_at_k(actual, predicted, k=10):\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    predicted = predicted[:k]\n",
    "    return 1.0 if len(set(predicted) & set(actual)) > 0 else 0.0\n",
    "\n",
    "def reciprocal_rank_at_k(actual, predicted, k=10):\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    predicted = predicted[:k]\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual:\n",
    "            return 1.0 / (i + 1.0)\n",
    "    return 0.0\n",
    "def evaluate_recommendations(ground_truth, recommendations, k=5, rmse_impli=None, time_implicity=None):\n",
    "    metrics = {\n",
    "        'Truncated Precision@K': np.mean([truncated_precision_at_k(a, p, k) for a, p in zip(ground_truth, recommendations)]),\n",
    "        'Truncated Average Precision@K': np.mean([truncated_average_precision_at_k(a, p, k) for a, p in zip(ground_truth, recommendations)]),\n",
    "        'Hit@K': np.mean([hit_at_k(a, p, k) for a, p in zip(ground_truth, recommendations)]),\n",
    "        'Reciprocal Rank@K': np.mean([reciprocal_rank_at_k(a, p, k) for a, p in zip(ground_truth, recommendations)]),\n",
    "        'RMSE': rmse_impli,\n",
    "        'Tiempo Recomendación': time_implicity\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "metrics_imp = evaluate_recommendations(ground_truth_imp, recommendations_imp, k=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T22:32:23.077560Z",
     "start_time": "2024-06-23T22:32:22.515445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "                               Implicit\nMetrics                                \nTruncated Precision@K          0.002752\nTruncated Average Precision@K  0.001182\nHit@K                          0.021931\nReciprocal Rank@K              0.007583\nRMSE                                NaN\nTiempo Recomendación                NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Implicit</th>\n    </tr>\n    <tr>\n      <th>Metrics</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Truncated Precision@K</th>\n      <td>0.002752</td>\n    </tr>\n    <tr>\n      <th>Truncated Average Precision@K</th>\n      <td>0.001182</td>\n    </tr>\n    <tr>\n      <th>Hit@K</th>\n      <td>0.021931</td>\n    </tr>\n    <tr>\n      <th>Reciprocal Rank@K</th>\n      <td>0.007583</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Tiempo Recomendación</th>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame.from_dict(metrics_imp, orient='index', columns=['Implicit']).rename_axis('Metrics')\n",
    "metrics_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T22:32:23.971377Z",
     "start_time": "2024-06-23T22:32:23.957161Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
